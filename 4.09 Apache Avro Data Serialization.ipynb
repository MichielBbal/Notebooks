{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad097636-dcde-437e-a447-27e8c313e1eb",
   "metadata": {},
   "source": [
    "# 4.09 Apache Avro Data Serialization\n",
    "\n",
    "More on avro:\n",
    "- https://www.oreilly.com/content/the-problem-of-managing-schemas/\n",
    "- https://www.confluent.io/blog/avro-kafka-data/\n",
    "\n",
    "\n",
    "Avro provides:\n",
    "\n",
    "- Rich data structures.\n",
    "- A compact, fast, binary data format.\n",
    "- A container file, to store persistent data.\n",
    "- Remote procedure call (RPC).\n",
    "- Simple integration with dynamic languages. Code generation is not required to read or write data files nor to use or implement RPC protocols. Code generation as an optional optimization, only worth implementing for statically typed languages.\n",
    "\n",
    "Benefits of Avro:\n",
    "- It has a direct mapping to and from JSON\n",
    "- It has a very compact format. The bulk of JSON, repeating every field name with every single record, is what makes JSON inefficient for high-volume usage.\n",
    "- It is very fast.\n",
    "- It has great bindings for a wide variety of programming languages so you can generate Java objects that make working with event data easier, but it does not require code generation so tools can be written generically for any data stream.\n",
    "- It has a rich, extensible schema language defined in pure JSON\n",
    "- It has the best notion of compatibility for evolving your data over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea074cd-c4c8-45ba-85ad-23f281415155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting avro\n",
      "  Downloading avro-1.11.0.tar.gz (83 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: avro\n",
      "  Building wheel for avro (pyproject.toml): started\n",
      "  Building wheel for avro (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for avro: filename=avro-1.11.0-py2.py3-none-any.whl size=115925 sha256=df9d7d863e6fc24b8b594a4a06f2273ecdd567fec32b8810b2e3af52f41b2b75\n",
      "  Stored in directory: c:\\users\\31653\\appdata\\local\\pip\\cache\\wheels\\9a\\a5\\9b\\d100e4bd3ef9697b2f955616260c77cb136f8cd2fc89533c63\n",
      "Successfully built avro\n",
      "Installing collected packages: avro\n",
      "Successfully installed avro-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41cb570-1a6f-4c00-be6b-1936d8e8636d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import avro\n",
    "print(avro.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f69dac-802e-4a1e-a2bd-21b1812c647a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaParseException",
     "evalue": "Error parsing JSON: b'', error = Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\avro\\schema.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(json_string, validate_enum_symbols)\u001b[0m\n\u001b[0;32m   1199\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m         \u001b[0mjson_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1201\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSchemaParseException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18344/1687602075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mavro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatumReader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatumWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mschema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user.avsc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"users.avro\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatumWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\avro\\schema.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(json_string, validate_enum_symbols)\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[0mjson_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mavro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSchemaParseException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Error parsing JSON: {json_string}, error = {e}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmake_avsc_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_enum_symbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSchemaParseException\u001b[0m: Error parsing JSON: b'', error = Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import avro.schema\n",
    "from avro.datafile import DataFileReader, DataFileWriter\n",
    "from avro.io import DatumReader, DatumWriter\n",
    "\n",
    "schema = avro.schema.parse(open(\"user.avsc\", \"rb\").read())\n",
    "\n",
    "writer = DataFileWriter(open(\"users.avro\", \"wb\"), DatumWriter(), schema)\n",
    "writer.append({\"name\": \"Alyssa\", \"favorite_number\": 256})\n",
    "writer.append({\"name\": \"Ben\", \"favorite_number\": 7, \"favorite_color\": \"red\"})\n",
    "writer.close()\n",
    "\n",
    "reader = DataFileReader(open(\"users.avro\", \"rb\"), DatumReader())\n",
    "for user in reader:\n",
    "    print(user)\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829165ac",
   "metadata": {},
   "source": [
    "## 2. Wikipedia example\n",
    "\n",
    "The English wikipedia has a nice example for avro: \n",
    "https://en.wikipedia.org/wiki/Apache_Avro\n",
    "\n",
    "I'have created a file called user.avsc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24240e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user.avsc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "my_avscs=glob.glob('*.avsc')\n",
    "my_avscs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db54941b-e4b8-4273-afbf-9e428dd47526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the avsc file\n",
    "%pycat C:\\\\Users\\\\31653\\\\Documents\\\\GitHub\\\\Notebooks\\user.avsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09403de7-87be-464d-b61b-ece86a06f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import avro.schema\n",
    "from avro.datafile import DataFileReader, DataFileWriter\n",
    "from avro.io import DatumReader, DatumWriter\n",
    "\n",
    "schema = avro.schema.parse(open(\"user.avsc\", \"rb\").read())  # need to know the schema to write. According to 1.8.2 of Apache Avro\n",
    "\n",
    "writer = DataFileWriter(open(\"users.avro\", \"wb\"), DatumWriter(), schema)\n",
    "writer.append({\"name\": \"Alyssa\", \"favorite_number\": 256})\n",
    "writer.append({\"name\": \"Ben\", \"favorite_number\": 8, \"favorite_color\": \"red\"})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7074f940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['users.avro']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "my_avros=glob.glob('*.avro')\n",
    "my_avros\n",
    "# One cannot inspect this file as it is a binary format file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da30d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alyssa', 'favorite_number': 256, 'favorite_color': None}\n",
      "{'name': 'Ben', 'favorite_number': 8, 'favorite_color': 'red'}\n"
     ]
    }
   ],
   "source": [
    "#deserialization\n",
    "reader = DataFileReader(open(\"users.avro\", \"rb\"), DatumReader())  # the schema is embedded in the data file\n",
    "for user in reader:\n",
    "    print(user)\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7c1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
