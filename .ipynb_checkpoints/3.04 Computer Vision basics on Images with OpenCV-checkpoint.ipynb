{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michiels OpenCV tutorial\n",
    "\n",
    "This is a short tutorial on OpenCV, the most widely used python library for Computer Vision.\n",
    "OpenCV can be used to get data out of an image. \n",
    "\n",
    "This tutorial uses several of the OpenCV techniques for a.o. image enhancement, object detection and classification. \n",
    "\n",
    "\n",
    "## Content of this tutorial\n",
    "\n",
    "0. Install packages\n",
    "\n",
    "### Images\n",
    "1. My first OpenCV script \n",
    "2. Resize and convert image\n",
    "3. Printing a rectangle on an image\n",
    "4. Tresholding\n",
    "5. FindContours script\n",
    "6. Blob detection\n",
    "7. Histogram of an image\n",
    "8. Hugh line transform\n",
    "9. Masking\n",
    "10. \n",
    "\n",
    "\n",
    "\n",
    "### Video\n",
    "- run a webcam / PyCam\n",
    "- change webcam params & add datetime\n",
    "- Hough Line P transformations\n",
    "- masking parts of an image\n",
    "- Find lane lines on an image with Canny Edge and Hough Line P\n",
    "- Haar cascade for faces and stop signs\n",
    "\n",
    "### Projects:\n",
    "- Ball tracking project / Robokeeper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install OpenCV and other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment and install necessary packages\n",
    "#!pip install numpy\n",
    "#!pip install scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. My first OpenCV script\n",
    "Just a simple script to import an image and show it\n",
    "\n",
    "Make sure you have your pics to localhost:8888 jupyter notebook folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is just a basic script to open and show an image \n",
    "# The script will open a new window.\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "\n",
    "# load the image\n",
    "img = cv2.imread('opencv.png') # read the picture from localhost:8888 jupyter notebook folder\n",
    "# show the image\n",
    "cv2.imshow('image', img) #show the image in a pop up (pop-up)\n",
    "\n",
    "cv2.waitKey(0) #To keep this window open. 0 = never ending.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('opencv.png')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic operators source: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_core/py_basic_ops/py_basic_ops.html\n",
    "print(f'image shape = {img.shape}') # returns rows, columns and channels (if image is color)\n",
    "print(f'Image size = {img.shape[0:2]}')\n",
    "print(f'image size = {img.size}') # returns no of pixels\n",
    "print(\"Image type = \" + str(type(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the values for blue, green, red\n",
    "b,g,r, = cv2.split(img)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resize and convert image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METADATA: Image type=<class 'numpy.ndarray'> | size=(350, 550)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resize the image. We will use an image from scipy.\n",
    "import scipy.misc\n",
    "import cv2 # import the OpenCV library\n",
    "img = scipy.misc.face() # haal de wasbeer foto op uit SciPy module en benoem deze als 'img'\n",
    "\n",
    "#option 1: relative resizing at 0.75 of original\n",
    "newImg1 = cv2.resize(img, (0,0), fx=0.75, fy=0.75)\n",
    "#optie 2: absoluut\n",
    "newImg2 = cv2.resize(img, (550, 350)) #eerst img aanroepen, dan aantal pixels \n",
    "print(\"METADATA: \"\"Image type=\" + str(type(newImg))+ \" | size=\"+str(newImg.shape[0:2]))\n",
    "cv2.imshow('resized image', newImg1) #show the image in new window\n",
    "cv2.waitKey(5) #close after 5 seconds\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the opencv image to gray \n",
    "import cv2\n",
    "img = cv2.imread('opencv.png')\n",
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #there is also RGB2GRAY !\n",
    "cv2.imshow('gray', gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding elements to an image (rectangle, text)\n",
    "\n",
    "When working with images you want to have the possibility of adding shapes and text to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a rectangle and print it on the image\n",
    "import cv2 \n",
    "   \n",
    "# load the image\n",
    "image = cv2.imread('opencv.png') # Reading an image in default mode\n",
    "\n",
    "# Draw a rectangle with blue line borders of thickness of 2 px\n",
    "# initialize\n",
    "window_name = 'Image'  # Window name in which image is displayed\n",
    "start_point = (30, 5)   # x, y of left top corner of the rectangle \n",
    "end_point = (250, 310) #x, y the bottom right corner of rectangle\n",
    "color = (255, 0, 0)    # frame color in BGR \n",
    "thickness = 2          # Line thickness of 2 px \n",
    "  \n",
    "# Using cv2.rectangle() method\n",
    "image = cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "  \n",
    "# Displaying the image \n",
    "cv2.imshow(window_name, image) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('opencv.png') # Reading an image in default mode\n",
    "\n",
    "#set params\n",
    "text= 'Michiel'\n",
    "location = (10,100)\n",
    "#font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color =  (255, 0, 255)\n",
    "thickness = 2\n",
    "lineType = cv2.LINE_AA\n",
    "\n",
    "#Add text to image\n",
    "\n",
    "image = cv2.putText(image,text,location,font,fontScale,color,thickness, lineType)\n",
    "# Displaying the image \n",
    "cv2.imshow('img', image) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tresholding\n",
    "source: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('opencv.png',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "\n",
    "\n",
    "ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find contours\n",
    "source 1: https://www.youtube.com/watch?v=FbR9Xr0TVdY\n",
    "source 2: https://likegeeks.com/python-image-processing#Get-image-contour \n",
    "\n",
    "The cell below will draw a contour around an image and will count the number of contours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#load the picture and convert to gray. \n",
    "img = cv2.imread('opencv.png')\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#define ret and treshold using the gray image, with 127 of max 255\n",
    "ret, thresh = cv2.threshold(imgray, 200, 255, 0)\n",
    "#find the contours\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#draw the image, use the original color image\n",
    "img_contour = cv2.drawContours(img, contours, -1, (255,0,255), 3) #-1= all contours, color, thickness\n",
    "\n",
    "#print (contours)\n",
    "cv2.imshow('Image', img_contour)\n",
    "print(\"Number of contours = \" + str(len(contours))) #len: list elements number van contour\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Blob detection\n",
    "Source: https://github.com/spmallick/learnopencv/tree/master/BlobDetector\n",
    "\n",
    "A 'blob' is a group of pixels in an image that share a property, for example same (gray scale) color value. We can use the blob detection function to identify these blobs, draw a circle around (and optionally count them). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# Standard imports\n",
    "import cv2\n",
    "import numpy as np;\n",
    "# Read image\n",
    "im = cv2.imread(\"blob.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Setup SimpleBlobDetector parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 10\n",
    "params.maxThreshold = 200\n",
    "\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = 1500\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.87\n",
    "    \n",
    "# Filter by Inertia\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "# Create a detector with the parameters\n",
    "ver = (cv2.__version__).split('.')\n",
    "if int(ver[0]) < 3 :\n",
    "\tdetector = cv2.SimpleBlobDetector(params)\n",
    "else : \n",
    "\tdetector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "\n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(im)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures\n",
    "# the size of the circle corresponds to the size of blob\n",
    "\n",
    "im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Show blobs\n",
    "cv2.imshow(\"Keypoints\", im_with_keypoints)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source https://www.youtube.com/watch?v=3D7O_kZi8-o&t=4s\n",
    "\n",
    "# use HSV = Hue, Saturation and Value aka hex color\n",
    "# Hue is color components (range 0-360)\n",
    "# Saturation is the amount of color (0-100%)\n",
    "# Value is basically the brightness (0-100%)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x): #callback function\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('Tracking') #ISSUE NOT ALL TRACKBARS ARE SHOWN!\n",
    "cv2.createTrackbar(\"LH\", 'Tracking', 0, 255, nothing) #LowerHue\n",
    "cv2.createTrackbar(\"LS\", 'Tracking', 0, 255, nothing) #LowerSat\n",
    "cv2.createTrackbar(\"LV\", 'Tracking', 0, 255, nothing) #LowerVal\n",
    "cv2.createTrackbar(\"UH\", 'Tracking', 255, 255, nothing)\n",
    "cv2.createTrackbar(\"LS\", 'Tracking', 255, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", 'Tracking', 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    frame = cv2.imread('OpenCV_rgb.png') # import an RGB image here!!\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h= cv2.getTrackbarPos('LH', 'Tracking')\n",
    "    l_s= cv2.getTrackbarPos('LS', 'Tracking')\n",
    "    l_v= cv2.getTrackbarPos('LV', 'Tracking')\n",
    "    \n",
    "    u_h= cv2.getTrackbarPos('LH', 'Tracking')\n",
    "    u_s= cv2.getTrackbarPos('LS', 'Tracking')\n",
    "    u_v= cv2.getTrackbarPos('LV', 'Tracking')\n",
    "    \n",
    "    l_b= np.array([110,50,50])#this is for the blue smartie lower_limit_blue original: (110,50,50)\n",
    "    u_b= np.array([130,255,255]) #oroginal (130,255,255)\n",
    "    \n",
    "    mask = cv2.inRange(hsv, l_b, u_b) #define a mask\n",
    "    \n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask) #bitwise res=result\n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('res', res)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key ==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. OpenCV Histograms with cv2.split, matplot lib. Also to count colors\n",
    "Source: https://www.youtube.com/watch?v=F9TZb0XBow0\n",
    "\n",
    "Rather complicated way of counting colors. It's easier to use np.asarray function (see Numpy tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ISSUE: remove 0 and 255 values at end of range!\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img =cv2.imread('opencv.png')\n",
    "\n",
    "b,g,r = cv2.split(img)\n",
    "#print(b[0])\n",
    "#cv2.imshow('img', img)\n",
    "#printcv2.imshow('b', b)\n",
    "#cv2.imshow('g', g)\n",
    "#printcv2show('r', r)\n",
    "\n",
    "plt.hist(b.ravel(), 256, [0,256])\n",
    "plt.hist(g.ravel(), 256, [0,256])\n",
    "#plt.hist(r.ravel(), 256, [0,256])\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('opencv.png')\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "     histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "     plt.plot(histr,color = col)\n",
    "     plt.xlim([0,256])\n",
    "plt.show()\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hough Line P Transformations\n",
    "\n",
    "source: https://www.youtube.com/watch?v=rVBVqVmHtfc&list=PLS1QulWo1RIa7D1O6skqDQ-JZ1GGHKK-K&index=34\n",
    "\n",
    "This script will identify lines in an image using the 'Hough Line P' transformation. See wikpedia: https://en.wikipedia.org/wiki/Hough_transform for more info.\n",
    "\n",
    "The function is cv2.HoughLinesP, which takes the following arguments:\n",
    "rho = Distance resolution of the accumulator in pixels\n",
    "theta = Angle resolution of the accumulator in radians\n",
    "minLineLength\n",
    "MaxLineGap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "\n",
    "img_big = cv2.imread('road2.jpg')\n",
    "#img = cv2.resize(img_big)\n",
    "img = cv2.resize(img_big, (1280,720), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50,150, apertureSize = 3)\n",
    "#cv2.imshow('edges', edges)\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100, minLineLength=100,maxLineGap=10)\n",
    "\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "    \n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "#cv2.imshow('image', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic webcam script\n",
    "\n",
    "https://www.youtube.com/watch?v=-RtVZsCvXAQ&list=PLS1QulWo1RIa7D1O6skqDQ-JZ1GGHKK-K&index=5\n",
    "\n",
    "Use this script to run a webcam. use the command 'q' to quit the webcam stream.\n",
    "This script will record the movie to an output.avi file.\n",
    "And it will also print the frame properties width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a video script and use 'q' to quit the script. \n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0); #0 is the default camera\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480))\n",
    "\n",
    "while (cap.isOpened()): # this will show the frame infinitively\n",
    "    ret, frame = cap.read() # ret=true/false, create a frame\n",
    "    \n",
    "    if ret == True:\n",
    "       #print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "       #print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "           \n",
    "       out.write(frame)\n",
    "       gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#to convert to gray\n",
    "       cv2.imshow('frame', frame)\n",
    "       #cv2.imshow('frame', gray)\n",
    "    \n",
    "       if cv2.waitKey(1) & 0xFF == ord('q'): #0xFF is a mask; ord\n",
    "           break\n",
    "    else:\n",
    "        break\n",
    "cap.release() # end the ca\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change params of camera and add date/time to output\n",
    "Open CV Camera Parameters in OpenCV python + show date / time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "cap.set(3, 1280) #3 is associated number for WIDTH\n",
    "cap.set(4, 720) # 4 is no. for HEIGHT\n",
    "# camera automatically adjusts resolution\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = \"Width: \" + str(cap.get(3)) + \" Height:\" + str(cap.get(4)) # to print width + height in image\n",
    "        datet = str(datetime.datetime.now()) # to print datetime \n",
    "        #Syntax: cv2.putText(image, text, origin, font, fontScale, color, thickness, lineType)\n",
    "        frame = cv2.putText(frame, text, (10,50), font , 1, \n",
    "                            (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using HSV with lower and upper limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([100,100,100]) #blue 110,50,50\n",
    "    upper_blue = np.array([255,255,255]) #blue 130,255,255\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking the noisy parts of the image\n",
    "Source : https://www.youtube.com/watch?v=yvfI4p6Wyvk&list=PLS1QulWo1RIa7D1O6skqDQ-JZ1GGHKK-K&index=35\n",
    "\n",
    "You only want to use the relevant parts of the image and mask the other part.\n",
    "This script below will create a mask and show only the relevant part of the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_big = cv2.imread('road2.jpg')\n",
    "img = cv2.resize(img_big, (1280,720), interpolation = cv2.INTER_AREA)\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(img.shape) # print the shape of the image\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "\n",
    "region_of_interest_vertices = [\n",
    "    (0, 720),\n",
    "    (0, 500),\n",
    "    (640,350),\n",
    "    (1280, 500),\n",
    "    (1280, 720)\n",
    "]\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    channel_count = img.shape[2]\n",
    "    match_mask_color = (255,)* channel_count\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "cropped_image = region_of_interest(img, np.array([region_of_interest_vertices], np.int32))\n",
    "plt.imshow(img), plt.imshow(cropped_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find lane lines on image with Canny Edge en Hough Line P\n",
    "\n",
    "In the script below we will find the lines in two steps:\n",
    "1) apply Canny Edge detection\n",
    "2) apply Hough Line P transformations\n",
    "\n",
    "We will also define a region_of_interest to just show the lines in that part of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    #channel_count = img.shape[2]\n",
    "    match_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_the_lines(img, lines):\n",
    "    img = np.copy(img)\n",
    "    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(blank_image, (x1, y1), (x2, y2), (255,0,0), thickness=5)\n",
    "\n",
    "    img = cv2.addWeighted(img, 0.8, blank_image, 1, 0.0)\n",
    "    return img\n",
    "            \n",
    "img_big = cv2.imread('road2.jpg')\n",
    "image = cv2.resize(img_big, (1280,720), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "print(image.shape) # print the shape of the image\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "\n",
    "region_of_interest_vertices = [\n",
    "    (0, 720),\n",
    "    (0, 500),\n",
    "    (640,350),\n",
    "    (1280, 500),\n",
    "    (1280, 720)\n",
    "]\n",
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "canny_image = cv2.Canny(gray_image, 100, 200)\n",
    "cropped_image = region_of_interest(canny_image, np.array([region_of_interest_vertices], np.int32))\n",
    "\n",
    "lines = cv2.HoughLinesP(cropped_image, \n",
    "                       rho=6,\n",
    "                       theta=np.pi/60,\n",
    "                       threshold =160,\n",
    "                       lines=np.array([]),\n",
    "                       minLineLength=40,\n",
    "                       maxLineGap=25)\n",
    "\n",
    "image_with_lines = draw_the_lines(img, lines)\n",
    "plt.imshow(image_with_lines)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar cascade image classifier to detect a face and stop signs.\n",
    "\n",
    "Source: Youtube  https://www.youtube.com/watch?v=88HdqNDQsEk \n",
    "\n",
    "You can find the haarcascade of OpenCV here: https://github.com/opencv/opencv/tree/master/data/haarcascades \n",
    "Download via 'Raw' en save in opencv2 project (localhost:8888 for jupyter notebooks)\n",
    "\n",
    "Stop signs: download a haar cascade xml from https://github.com/Dexter2389/Stop-sign-Haar-cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import cv2\n",
    "\n",
    "#face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier('haar_cascade_stop.xml')\n",
    "#face_cascade = cv2.CascadeClassifier('traffic_light.xml') # traffic light not working\n",
    "\n",
    "cap = cv2.VideoCapture(0) #0 is the default camera\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    nstops = 0\n",
    "    for (x, y, w, h) in faces:\n",
    "        rect = cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "        \n",
    "        area = w*h\n",
    "        #Syntax: cv2.putText(image, text, origin, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "        #font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        #cv2.putText(img, area, (10,50) , font, 1, (255,0,0) ,2, cv2.LINE_AA)\n",
    "        print(area)\n",
    "        sleep(0.2)\n",
    "        if area > 5000:  # if the area of bounding box is larger than certain value stop the car\n",
    "            nstops = nstops + 1\n",
    "                \n",
    "    # Display the output)\n",
    "    cv2.imshow('img', img)\n",
    "    \n",
    "    if nstops == 1:\n",
    "        print(\"STOP\")\n",
    "        sleep(3)\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video with canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a script to do canny edge etc on video\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = cv2.VideoCapture(\"road_car_view.mp4\") #filename = road_car_view.mp4\n",
    "\n",
    "while True:\n",
    "    ret, orig_frame = video.read()\n",
    "    if not ret:\n",
    "        video = cv2.VideoCapture(\"road_car_view.mp4\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.GaussianBlur(orig_frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    low_yellow = np.array([18, 94, 140])\n",
    "    up_yellow = np.array([48, 255, 255])\n",
    "    mask = cv2.inRange(hsv, low_yellow, up_yellow)\n",
    "    edges = cv2.Canny(mask, 75, 150)\n",
    "\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, maxLineGap=50)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"edges\", edges)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ball tracker\n",
    "\n",
    "https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tracking window niet goed!\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "img = np.zeros((300,512,3), np.uint8) #create an image using numpy zeros array\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.createTrackbar(\"B\", 'image', 0, 255, nothing) #value, windowname, initialvalue, max val, call back\n",
    "cv2.createTrackbar(\"G\", 'image', 0, 255, nothing) #value, windowname, initialvalue, max val, call back\n",
    "cv2.createTrackbar(\"R\", 'image', 0, 255, nothing) #value, windowname, initialvalue, max val, call back\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image', img)\n",
    "    k= cv2.waitKey(1) & 0xFF\n",
    "    if k ==27: #print escape key to break the loop\n",
    "        break\n",
    "        \n",
    "    #current positions of trackbars\n",
    "    b = cv.getTrackbarPos('B', 'image') #name trackbar, name window\n",
    "    g = cv.getTrackbarPos('G', 'image') #name trackbar, name window\n",
    "    r = cv.getTrackbarPos('R', 'image') #name trackbar, name window\n",
    "    \n",
    "    img[:] = [b,g,r,]\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from collections import deque\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-v\", \"--video\",\n",
    "\thelp=\"ball_tracking_example.mp4\")\n",
    "ap.add_argument(\"-b\", \"--buffer\", type=int, default=64,\n",
    "\thelp=\"max buffer size\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from collections import deque\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-v\", \"--video\", help=\"ball_tracking_example.mp4\")\n",
    "#ap.add_argument(\"-b\", \"--buffer\", type=int, default=64,\n",
    "\t#help=\"max buffer size\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# define the lower and upper boundaries of the \"green\"\n",
    "# ball in the HSV color space, then initialize the\n",
    "# list of tracked points\n",
    "greenLower = (29, 86, 6)\n",
    "greenUpper = (64, 255, 255)\n",
    "pts = deque(maxlen=args[\"buffer\"])\n",
    "\n",
    "# if a video path was not supplied, grab the reference\n",
    "# to the webcam\n",
    "if not args.get(\"video\", False):\n",
    "\tvs = VideoStream(src=0).start()\n",
    "\n",
    "# otherwise, grab a reference to the video file\n",
    "else:\n",
    "\tvs = cv2.VideoCapture(args[\"video\"])\n",
    "\n",
    "# allow the camera or video file to warm up\n",
    "time.sleep(2.0)\n",
    "\n",
    "# keep looping\n",
    "while True:\n",
    "\t# grab the current frame\n",
    "\tframe = vs.read()\n",
    "\n",
    "\t# handle the frame from VideoCapture or VideoStream\n",
    "\tframe = frame[1] if args.get(\"video\", False) else frame\n",
    "\n",
    "\t# if we are viewing a video and we did not grab a frame,\n",
    "\t# then we have reached the end of the video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\n",
    "\t# resize the frame, blur it, and convert it to the HSV\n",
    "\t# color space\n",
    "\tframe = imutils.resize(frame, width=600)\n",
    "\tblurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "\thsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\t# construct a mask for the color \"green\", then perform\n",
    "\t# a series of dilations and erosions to remove any small\n",
    "\t# blobs left in the mask\n",
    "\tmask = cv2.inRange(hsv, greenLower, greenUpper)\n",
    "\tmask = cv2.erode(mask, None, iterations=2)\n",
    "\tmask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "\t# find contours in the mask and initialize the current\n",
    "\t# (x, y) center of the ball\n",
    "\tcnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    "\tcenter = None\n",
    "\n",
    "\t# only proceed if at least one contour was found\n",
    "\tif len(cnts) > 0:\n",
    "\t\t# find the largest contour in the mask, then use\n",
    "\t\t# it to compute the minimum enclosing circle and\n",
    "\t\t# centroid\n",
    "\t\tc = max(cnts, key=cv2.contourArea)\n",
    "\t\t((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "\t\tM = cv2.moments(c)\n",
    "\t\tcenter = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "\t\t# only proceed if the radius meets a minimum size\n",
    "\t\tif radius > 10:\n",
    "\t\t\t# draw the circle and centroid on the frame,\n",
    "\t\t\t# then update the list of tracked points\n",
    "\t\t\tcv2.circle(frame, (int(x), int(y)), int(radius),\n",
    "\t\t\t\t(0, 255, 255), 2)\n",
    "\t\t\tcv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "\t# update the points queue\n",
    "\tpts.appendleft(center)\n",
    "\n",
    "\t# loop over the set of tracked points\n",
    "\tfor i in range(1, len(pts)):\n",
    "\t\t# if either of the tracked points are None, ignore\n",
    "\t\t# them\n",
    "\t\tif pts[i - 1] is None or pts[i] is None:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# otherwise, compute the thickness of the line and\n",
    "\t\t# draw the connecting lines\n",
    "\t\tthickness = int(np.sqrt(args[\"buffer\"] / float(i + 1)) * 2.5)\n",
    "\t\tcv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\n",
    "\t# show the frame to our screen\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the 'q' key is pressed, stop the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "# if we are not using a video file, stop the camera video stream\n",
    "if not args.get(\"video\", False):\n",
    "\tvs.stop()\n",
    "\n",
    "# otherwise, release the camera\n",
    "else:\n",
    "\tvs.release()\n",
    "\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Camera:\n",
    "    \"\"\"Camera\"\"\"\n",
    "    def __init__(self, camera_index):\n",
    "        self.cap = None\n",
    "        self.camera_index = camera_index\n",
    "        \n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(self.camera_index)\n",
    "        except:\n",
    "            print(\"Failed connect to camera \",self.camera_index)\n",
    "\n",
    "    def disconnect(self):\n",
    "        try:\n",
    "            self.cap.release()\n",
    "        except:\n",
    "            print(\"Failed disconnect to camera \",self.camera_index)\n",
    "            \n",
    "    def get_frame(self):\n",
    "        if(self.cap is None):\n",
    "            print(\"Camera is not open\")\n",
    "            return\n",
    "        ret, frame = self.cap.read()\n",
    "        return ret, frame\n",
    "    \n",
    "class Tracker:\n",
    "    \"\"\"Tracker\"\"\"\n",
    "    def __init__(self):\n",
    "        self.upper_threshold = None\n",
    "        self.lower_threshold = None\n",
    "\n",
    "    def set_threshold(self, upper_threshold, lower_threshold):\n",
    "        self.upper_threshold = upper_threshold\n",
    "        self.lower_threshold = lower_threshold\n",
    "        \n",
    "    def threshold(self, frame):\n",
    "        return frame\n",
    "\n",
    "    def track(self, frame):\n",
    "        ball_distance = 0\n",
    "        ball_degree = 0\n",
    "        return frame, ball_distance, ball_degree\n",
    "    \n",
    "class Display:\n",
    "    \"\"\"Display\"\"\"\n",
    "    def __init__(self, name, height, weight):\n",
    "        self.name = name\n",
    "        self.height = height\n",
    "        self.weight = weight\n",
    "        cv2.namedWindow(name)\n",
    "        \n",
    "    def show(self,image):\n",
    "        cv2.imshow(self.name, image)\n",
    "\n",
    "class Input:\n",
    "    \"\"\"Input\"\"\"\n",
    "    def __init__(self):\n",
    "        self.use_default = 1\n",
    "        self.default_upper = np.array([50,255,255])\n",
    "        self.default_lower = np.array([0,170,170])\n",
    "        self.upper_h = 255\n",
    "        self.lower_h = 0\n",
    "        self.upper_s = 255\n",
    "        self.lower_s = 0\n",
    "        self.upper_v = 255\n",
    "        self.lower_v = 0\n",
    "        self.min_value = 0\n",
    "        self.max_value = 1000\n",
    "        \n",
    "    def nothing(self,x):\n",
    "        pass\n",
    "    \n",
    "    def create_trackbar(self):\n",
    "        self.threshold = Display('Threshold',640,480)\n",
    "        cv2.createTrackbar('Use Default','Threshold',0,1,self.nothing)\n",
    "        cv2.createTrackbar('Upper H','Threshold',0,179,self.nothing)\n",
    "        cv2.createTrackbar('Lower H','Threshold',0,179,self.nothing)\n",
    "        cv2.createTrackbar('Upper S','Threshold',0,255,self.nothing)\n",
    "        cv2.createTrackbar('Lower S','Threshold',0,255,self.nothing)\n",
    "        cv2.createTrackbar('Upper V','Threshold',0,255,self.nothing)\n",
    "        cv2.createTrackbar('Lower V','Threshold',0,255,self.nothing)\n",
    "        cv2.createTrackbar('Min Value','Threshold',0,10000,self.nothing)\n",
    "        cv2.createTrackbar('Max Value','Threshold',0,10000,self.nothing)\n",
    "        \n",
    "    def update_value(self):\n",
    "        self.use_default = cv2.getTrackbarPos('Use Default','Threshold')\n",
    "        self.upper_h = cv2.getTrackbarPos('Upper H','Threshold')\n",
    "        self.lower_h = cv2.getTrackbarPos('Lower H','Threshold')\n",
    "        self.upper_s = cv2.getTrackbarPos('Upper S','Threshold')\n",
    "        self.lower_s = cv2.getTrackbarPos('Lower S','Threshold')\n",
    "        self.upper_v = cv2.getTrackbarPos('Upper V','Threshold')\n",
    "        self.lower_v = cv2.getTrackbarPos('Lower V','Threshold')\n",
    "\n",
    "    def get_value(self):\n",
    "        if(self.use_default is 1):\n",
    "            return self.default_upper, self.default_lower\n",
    "        else:\n",
    "            return np.array([self.upper_h,self.upper_s,self.upper_v]), np.array([self.lower_h,self.lower_s,self.lower_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StepperMotor import *\n",
    "from Tracker import *\n",
    "from threading import Thread\n",
    "\n",
    "cam = Camera(0)\n",
    "inputs = Input()\n",
    "tracker = Tracker()\n",
    "motor = StepperMotor(\"COM3\",115200)\n",
    "display = Display(\"Display\",640,480)\n",
    "\n",
    "#Global Variable\n",
    "is_running = False\n",
    "is_ready_to_move = False\n",
    "is_move_done = False\n",
    "ball_distance = 0\n",
    "ball_degree = 0\n",
    "\n",
    "def get_input():\n",
    "    global is_running\n",
    "\n",
    "    is_running = True\n",
    "    \n",
    "    while(is_running):\n",
    "        inputs.update_value()\n",
    "        value = inputs.get_value()\n",
    "        time.sleep(0.1)\n",
    "        #print(value)\n",
    "\n",
    "def tracking():\n",
    "    global is_running, ball_distance, ball_degree\n",
    "\n",
    "    is_running = True\n",
    "    \n",
    "    cam.connect()\n",
    "    i = 0\n",
    "    while(is_running):\n",
    "        start = time.time()\n",
    "\n",
    "        ret, frame = cam.get_frame()\n",
    "        if ret is False:\n",
    "            print(\"No frame\")\n",
    "            continue\n",
    "\n",
    "        frame = tracker.threshold(frame)\n",
    "        frame, ball_distance, ball_degree = tracker.track(frame)\n",
    "        display.show(frame)\n",
    "        \n",
    "        end = time.time()\n",
    "        print(i,(end-start)*1000)\n",
    "        i = i +1\n",
    "    cam.disconnect()\n",
    "\n",
    "def move_motor():\n",
    "    global is_running,is_ready_to_move, is_move_done, ball_distance, ball_degree\n",
    "\n",
    "    is_running = True\n",
    "    \n",
    "    motor.connect()\n",
    "    \n",
    "    while(is_running):\n",
    "        if(is_ready_to_move and not is_move_done):\n",
    "            motor.move(ball_degree)\n",
    "        #print(ball_distance,ball_degree)\n",
    "        \n",
    "get_input_thread = Thread(target = get_input)\n",
    "tracking_thread = Thread(target = tracking)\n",
    "move_motor_thread = Thread(target = move_motor)\n",
    "\n",
    "inputs.create_trackbar()\n",
    "\n",
    "get_input_thread.start()\n",
    "tracking_thread.start()\n",
    "move_motor_thread.start()\n",
    "\n",
    "while(True):\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key is 27:\n",
    "        is_running = False\n",
    "        break\n",
    "    \n",
    "if(is_running is True):\n",
    "    is_running = False\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
