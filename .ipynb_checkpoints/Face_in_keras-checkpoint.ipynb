{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 15:02:05.283318: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_img' from 'keras.preprocessing.image' (/Users/michielbontenbal/.local/lib/python3.9/site-packages/keras/preprocessing/image.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m np_utils\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator, load_img, img_to_array, array_to_img \n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_img' from 'keras.preprocessing.image' (/Users/michielbontenbal/.local/lib/python3.9/site-packages/keras/preprocessing/image.py)"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De cel hieronder is de functie om de gezichten uit de fotos te knippen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import cv2\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "def image_get_faces(image_name, location):\n",
    "    image = cv2.imread(image_name)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt2.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(100, 100)\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        print(\"[INFO] Found {0} Faces.\".format(len(faces)), end=' ')\n",
    "        print((x, y, w, h), end=' ') \n",
    "        print(\"Object found, saved.\")\n",
    "        tempname = str(uuid.uuid4().hex)\n",
    "        clip = cv2.resize(image[y:y + h, x:x + w],(150,150))\n",
    "        cv2.imwrite(str(location) + tempname + '_faces.jpg', clip)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PATH_TO_PICTURES = ' Path to Pictures followed by \\\\*.jpg ' \n",
    "\n",
    "# example 'Z:\\\\Media\\\\Fotos\\\\2016-2018\\\\*.jpg'\n",
    "\n",
    "# let-op de faces-scrape folder bevat de ruwe images.\n",
    "# Copy de uiteindelijke imeges naar de faces2 folder en de \n",
    "# test images naar faces-test folder\n",
    "\n",
    "train_files = glob.glob(PATH_TO_PICTURES)            \n",
    "for img in train_files:\n",
    "    image_get_faces(img,'faces-scrape\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMG_DIM = (150, 150)\n",
    "\n",
    "# De labels worden uit het aantal verschillende filenamen gehaald.(de nummers en haakjes worden gewist)\n",
    "\n",
    "train_files = glob.glob('faces2\\\\*.jpg')\n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "train_labels = [fn.split('\\\\')[1].split('.')[0].rstrip(' (12345678900)') for fn in train_files]\n",
    "\n",
    "unknown_files = glob.glob('faces-test\\\\*.jpg')\n",
    "unknown_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in unknown_files]\n",
    "unknown_imgs = np.array(unknown_imgs)\n",
    "unknown_labels = [fn.split('\\\\')[1].split('.')[0].rstrip(' (12345678900)') for fn in unknown_files]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hieronder begint de data augmentation het genereren van extra images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen =  ImageDataGenerator(rescale=1./255, zoom_range=0.2, rotation_range=20,\n",
    "                                    width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, \n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "unknown_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# zet de namen om in de zogenaamde onehot encoding.\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "transformed_label = encoder.fit_transform(train_labels)\n",
    "unknown_transformed_label = encoder.transform(unknown_labels)\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs, transformed_label, batch_size=64)\n",
    "val_generator = val_datagen.flow(train_imgs, transformed_label,batch_size=64)\n",
    "unknown_generator = val_datagen.flow(unknown_imgs, unknown_transformed_label,batch_size=64)\n",
    "\n",
    "# letop als je een ander aantal personen hebt moet je dit aanpassen.\n",
    "def test_generator(generator, nr = 10 ):\n",
    "    names = [ 'Persoon 1' , 'Persoon 2'  , 'Persoon 3', 'Persoon 3']\n",
    "    fig, ax = plt.subplots(1,nr, figsize=(nr, 20), frameon=False)\n",
    "    vals, labs = next(generator)\n",
    "    for i in range(0,nr):\n",
    "        ax[i].imshow(vals[i])\n",
    "        ax[i].set_frame_on(False)\n",
    "        ax[i].set_title(names[np.argmax(labs[i])])\n",
    "        \n",
    "test_generator(unknown_generator, nr=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "# Kies hieronder ook eens ander net, of wat gebeurt er als je een getraind net neemt\n",
    "# Neem een geinitialiseert netwerk met imagenet weights \n",
    "# Werkt een ander netwerk beter b.v. Resnet e.e.a.\n",
    "\n",
    "input_shape = (150, 150, 3)\n",
    "vgg = vgg16.VGG16(include_top=False, weights=None, input_shape=input_shape)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "\n",
    "\n",
    "# Hieronder stel je in hoeveel lagen van het VGG netwerk je wil bij trainen. Nu werkt het niet\n",
    "# het netwerk heeft random weights en kan niet getraiond worden.\n",
    "\n",
    "vgg_model = Model(vgg.input, output)\n",
    "vgg_model.trainable = True\n",
    "set_trainable = True\n",
    "for layer in vgg_model.layers:\n",
    "    if layer.name in ['block5_conv_NOOOIIIT']:  # vanaf de naam van de layer tot aan outputlaag is te trainen.\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "vgg_model.summary() \n",
    "\n",
    "# Print layer status.\n",
    "pd.set_option('max_colwidth', None)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, GRU, Dropout\n",
    "from keras import optimizers\n",
    "import shutil as sh\n",
    "import tensorflow as tf\n",
    "\n",
    "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "sh.rmtree('logs',ignore_errors=True)\n",
    "callbacks = [tbCallBack]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vgg_model) # Stop het complete vgg model in het nieuwe model.\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))  # voeg je eigen lagen toe, of is dit genoeg?\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks = [tbCallBack]\n",
    "\n",
    "sh.rmtree('logs',ignore_errors=True)\n",
    "history = model.fit(train_generator,  steps_per_epoch=2, epochs=50,\n",
    "                              validation_data=unknown_generator, validation_steps=50,\n",
    "                              verbose=1,callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = next(unknown_generator)\n",
    "\n",
    "results = model.predict(x)\n",
    "\n",
    "names = [ 'Persoon 1' , 'Persoon 2' , 'Persoon 3', 'Persoon 4']\n",
    "tl = [ names[np.argmax(res)] for res in results] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,10, figsize=(30, 12))\n",
    "for i in range(0,10):\n",
    "    ax[i].imshow(x[i])\n",
    "    ax[i].set_title(tl[i])\n",
    "\n",
    "fig, ax = plt.subplots(1,10, figsize=(30, 12))\n",
    "for i in range(10,20):\n",
    "    ax[i-10].imshow(x[i])\n",
    "    ax[i-10].set_title(tl[i])\n",
    "\n",
    "fig, ax = plt.subplots(1,10, figsize=(30, 12))\n",
    "for i in range(20,30):\n",
    "    ax[i-20].imshow(x[i])\n",
    "    ax[i-20].set_title(tl[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De code hieronder laat zien hoe je een model kan opslaan en later weer gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Frozen-cnn-100ep-100bat-size100-perfect-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('Frozen-cnn-100ep-100bat-size100-perfect-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = next(unknown_generator)\n",
    "test_loss, test_acc = model.evaluate(x, y)\n",
    "\n",
    "tl = [ names[np.argmax(res)] for res in y] \n",
    "fig, ax = plt.subplots(1,31, figsize=(30, 12))\n",
    "for i in range(0,31):\n",
    "    ax[i].imshow(x[i])\n",
    "    ax[i].set_title(tl[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
