{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michiels OpenCV tutorial\n",
    "\n",
    "This is a short tutorial on OpenCV, the most widely used python library for Computer Vision.\n",
    "OpenCV can be used to get data out of an image. \n",
    "\n",
    "This tutorial uses several of the OpenCV techniques for a.o. image enhancement, object detection and classification. \n",
    "\n",
    "\n",
    "## Content of this tutorial\n",
    "\n",
    "0. Install packages\n",
    "1. Basic webcam script\n",
    "2. change webcam params & add datetime\n",
    "3. Hough Line P transformations\n",
    "4. masking parts of an image\n",
    "5. Find lane lines on an image with Canny Edge and Hough Line P\n",
    "6. Haar cascade for faces and stop signs\n",
    "\n",
    "### Projects:\n",
    "- Ball tracking project / Robokeeper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install OpenCV and other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment and install necessary packages\n",
    "#!pip install numpy\n",
    "#!pip install scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic webcam script\n",
    "\n",
    "https://www.youtube.com/watch?v=-RtVZsCvXAQ&list=PLS1QulWo1RIa7D1O6skqDQ-JZ1GGHKK-K&index=5\n",
    "\n",
    "Use this script to run a webcam. use the command 'q' to quit the webcam stream.\n",
    "This script will record the movie to an output.avi file.\n",
    "And it will also print the frame properties width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a video script and use 'q' to quit the script. \n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0); #0 is the default camera\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480))\n",
    "\n",
    "while (cap.isOpened()): # this will show the frame infinitively\n",
    "    ret, frame = cap.read() # ret=true/false, create a frame\n",
    "    \n",
    "    if ret == True:\n",
    "       #print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "       #print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "           \n",
    "       out.write(frame)\n",
    "       gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#to convert to gray\n",
    "       cv2.imshow('frame', frame)\n",
    "       #cv2.imshow('frame', gray)\n",
    "    \n",
    "       if cv2.waitKey(1) & 0xFF == ord('q'): #0xFF is a mask; ord\n",
    "           break\n",
    "    else:\n",
    "        break\n",
    "cap.release() # end the ca\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Change params of camera and add date/time to output\n",
    "Open CV Camera Parameters in OpenCV python + show date / time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "cap.set(3, 1280) #3 is associated number for WIDTH\n",
    "cap.set(4, 720) # 4 is no. for HEIGHT\n",
    "# camera automatically adjusts resolution\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = \"Width: \" + str(cap.get(3)) + \" Height:\" + str(cap.get(4)) # to print width + height in image\n",
    "        datet = str(datetime.datetime.now()) # to print datetime \n",
    "        #Syntax: cv2.putText(image, text, origin, font, fontScale, color, thickness, lineType)\n",
    "        frame = cv2.putText(frame, text, (10,50), font , 1, \n",
    "                            (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using HSV with lower and upper limits\n",
    "\n",
    "HSV is a feature of images. \n",
    "\n",
    "\n",
    "The HSV or Hue, Saturation, and Value of a given object is the color space associated with the object in OpenCV. \n",
    "\n",
    "The Hue in HSV represents the color, Saturation in HSV represents the greyness, and Value in HSV represents the brightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([100,100,100]) #blue 110,50,50\n",
    "    upper_blue = np.array([255,255,255]) #blue 130,255,255\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Video with Haar Cascade image classifier to detect a face and stop signs.\n",
    "\n",
    "Source: Youtube  https://www.youtube.com/watch?v=88HdqNDQsEk \n",
    "\n",
    "You can find the haarcascade of OpenCV here: https://github.com/opencv/opencv/tree/master/data/haarcascades \n",
    "Download via 'Raw' en save in opencv2 project (localhost:8888 for jupyter notebooks)\n",
    "\n",
    "Stop signs: download a haar cascade xml from https://github.com/Dexter2389/Stop-sign-Haar-cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4624\n",
      "4624\n",
      "4624\n",
      "5776\n",
      "STOP\n",
      "4356\n",
      "5184\n",
      "STOP\n",
      "4489\n",
      "5041\n",
      "STOP\n",
      "5329\n",
      "STOP\n",
      "4624\n",
      "7569\n",
      "STOP\n",
      "4096\n",
      "4761\n",
      "4489\n",
      "5184\n",
      "STOP\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nstops \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import cv2\n",
    "\n",
    "#face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier('haar_cascade_stop.xml')\n",
    "#face_cascade = cv2.CascadeClassifier('traffic_light.xml') # traffic light not working\n",
    "\n",
    "cap = cv2.VideoCapture(0) #0 is the default camera\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    nstops = 0\n",
    "    for (x, y, w, h) in faces:\n",
    "        rect = cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "        \n",
    "        area = w*h\n",
    "        #Syntax: cv2.putText(image, text, origin, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "        #font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        #cv2.putText(img, area, (10,50) , font, 1, (255,0,0) ,2, cv2.LINE_AA)\n",
    "        print(area)\n",
    "        sleep(0.2)\n",
    "        if area > 5000:  # if the area of bounding box is larger than certain value stop the car\n",
    "            nstops = nstops + 1\n",
    "                \n",
    "    # Display the output)\n",
    "    cv2.imshow('img', img)\n",
    "    \n",
    "    if nstops == 1:\n",
    "        print(\"STOP\")\n",
    "        sleep(3)\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Video with canny edge detection\n",
    "\n",
    "In this example we will use it to detect lines in a video of a car driving. \n",
    "This type of algorithms is used in user-assisted self driving cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-27 10:35:15--  https://github.com/rafutek/DrawRoad/blob/master/road_car_view.mp4\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: 'road_car_view.mp4'\n",
      "\n",
      "road_car_view.mp4       [ <=>                ] 132.97K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2023-01-27 10:35:15 (2.37 MB/s) - 'road_car_view.mp4' saved [136160]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/rafutek/DrawRoad/blob/master/road_car_view.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"road_car_view.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.Video('road_car_view.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a script to do canny edge etc on video\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = cv2.VideoCapture(\"road_car_view.mp4\") #filename = road_car_view.mp4\n",
    "\n",
    "while True:\n",
    "    ret, orig_frame = video.read()\n",
    "    if not ret:\n",
    "        video = cv2.VideoCapture(\"road_car_view.mp4\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.GaussianBlur(orig_frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    low_yellow = np.array([18, 94, 140])\n",
    "    up_yellow = np.array([48, 255, 255])\n",
    "    mask = cv2.inRange(hsv, low_yellow, up_yellow)\n",
    "    edges = cv2.Canny(mask, 75, 150)\n",
    "\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, maxLineGap=50)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"edges\", edges)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in progress: ball tracker\n",
    "\n",
    "https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tracking window niet goed!\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "img = np.zeros((300,512,3), np.uint8) #create an image using numpy zeros array\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.createTrackbar(\"B\", 'image', 0, 255, nothing) #value, windowname, initialvalue, max val, call back\n",
    "cv2.createTrackbar(\"G\", 'image', 0, 255, nothing) #value, windowname, initialvalue, max val, call back\n",
    "cv2.createTrackbar(\"R\", 'image', 0, 255, nothing) #value, windowname, initialvalue, max val, call back\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image', img)\n",
    "    k= cv2.waitKey(1) & 0xFF\n",
    "    if k ==27: #print escape key to break the loop\n",
    "        break\n",
    "        \n",
    "    #current positions of trackbars\n",
    "    b = cv.getTrackbarPos('B', 'image') #name trackbar, name window\n",
    "    g = cv.getTrackbarPos('G', 'image') #name trackbar, name window\n",
    "    r = cv.getTrackbarPos('R', 'image') #name trackbar, name window\n",
    "    \n",
    "    img[:] = [b,g,r,]\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from collections import deque\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-v\", \"--video\",\n",
    "\thelp=\"ball_tracking_example.mp4\")\n",
    "ap.add_argument(\"-b\", \"--buffer\", type=int, default=64,\n",
    "\thelp=\"max buffer size\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from collections import deque\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-v\", \"--video\", help=\"ball_tracking_example.mp4\")\n",
    "#ap.add_argument(\"-b\", \"--buffer\", type=int, default=64,\n",
    "\t#help=\"max buffer size\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# define the lower and upper boundaries of the \"green\"\n",
    "# ball in the HSV color space, then initialize the\n",
    "# list of tracked points\n",
    "greenLower = (29, 86, 6)\n",
    "greenUpper = (64, 255, 255)\n",
    "pts = deque(maxlen=args[\"buffer\"])\n",
    "\n",
    "# if a video path was not supplied, grab the reference\n",
    "# to the webcam\n",
    "if not args.get(\"video\", False):\n",
    "\tvs = VideoStream(src=0).start()\n",
    "\n",
    "# otherwise, grab a reference to the video file\n",
    "else:\n",
    "\tvs = cv2.VideoCapture(args[\"video\"])\n",
    "\n",
    "# allow the camera or video file to warm up\n",
    "time.sleep(2.0)\n",
    "\n",
    "# keep looping\n",
    "while True:\n",
    "\t# grab the current frame\n",
    "\tframe = vs.read()\n",
    "\n",
    "\t# handle the frame from VideoCapture or VideoStream\n",
    "\tframe = frame[1] if args.get(\"video\", False) else frame\n",
    "\n",
    "\t# if we are viewing a video and we did not grab a frame,\n",
    "\t# then we have reached the end of the video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\n",
    "\t# resize the frame, blur it, and convert it to the HSV\n",
    "\t# color space\n",
    "\tframe = imutils.resize(frame, width=600)\n",
    "\tblurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "\thsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\t# construct a mask for the color \"green\", then perform\n",
    "\t# a series of dilations and erosions to remove any small\n",
    "\t# blobs left in the mask\n",
    "\tmask = cv2.inRange(hsv, greenLower, greenUpper)\n",
    "\tmask = cv2.erode(mask, None, iterations=2)\n",
    "\tmask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "\t# find contours in the mask and initialize the current\n",
    "\t# (x, y) center of the ball\n",
    "\tcnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    "\tcenter = None\n",
    "\n",
    "\t# only proceed if at least one contour was found\n",
    "\tif len(cnts) > 0:\n",
    "\t\t# find the largest contour in the mask, then use\n",
    "\t\t# it to compute the minimum enclosing circle and\n",
    "\t\t# centroid\n",
    "\t\tc = max(cnts, key=cv2.contourArea)\n",
    "\t\t((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "\t\tM = cv2.moments(c)\n",
    "\t\tcenter = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "\t\t# only proceed if the radius meets a minimum size\n",
    "\t\tif radius > 10:\n",
    "\t\t\t# draw the circle and centroid on the frame,\n",
    "\t\t\t# then update the list of tracked points\n",
    "\t\t\tcv2.circle(frame, (int(x), int(y)), int(radius),\n",
    "\t\t\t\t(0, 255, 255), 2)\n",
    "\t\t\tcv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "\t# update the points queue\n",
    "\tpts.appendleft(center)\n",
    "\n",
    "\t# loop over the set of tracked points\n",
    "\tfor i in range(1, len(pts)):\n",
    "\t\t# if either of the tracked points are None, ignore\n",
    "\t\t# them\n",
    "\t\tif pts[i - 1] is None or pts[i] is None:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# otherwise, compute the thickness of the line and\n",
    "\t\t# draw the connecting lines\n",
    "\t\tthickness = int(np.sqrt(args[\"buffer\"] / float(i + 1)) * 2.5)\n",
    "\t\tcv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\n",
    "\t# show the frame to our screen\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the 'q' key is pressed, stop the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "# if we are not using a video file, stop the camera video stream\n",
    "if not args.get(\"video\", False):\n",
    "\tvs.stop()\n",
    "\n",
    "# otherwise, release the camera\n",
    "else:\n",
    "\tvs.release()\n",
    "\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Camera:\n",
    "    \"\"\"Camera\"\"\"\n",
    "    def __init__(self, camera_index):\n",
    "        self.cap = None\n",
    "        self.camera_index = camera_index\n",
    "        \n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(self.camera_index)\n",
    "        except:\n",
    "            print(\"Failed connect to camera \",self.camera_index)\n",
    "\n",
    "    def disconnect(self):\n",
    "        try:\n",
    "            self.cap.release()\n",
    "        except:\n",
    "            print(\"Failed disconnect to camera \",self.camera_index)\n",
    "            \n",
    "    def get_frame(self):\n",
    "        if(self.cap is None):\n",
    "            print(\"Camera is not open\")\n",
    "            return\n",
    "        ret, frame = self.cap.read()\n",
    "        return ret, frame\n",
    "    \n",
    "class Tracker:\n",
    "    \"\"\"Tracker\"\"\"\n",
    "    def __init__(self):\n",
    "        self.upper_threshold = None\n",
    "        self.lower_threshold = None\n",
    "\n",
    "    def set_threshold(self, upper_threshold, lower_threshold):\n",
    "        self.upper_threshold = upper_threshold\n",
    "        self.lower_threshold = lower_threshold\n",
    "        \n",
    "    def threshold(self, frame):\n",
    "        return frame\n",
    "\n",
    "    def track(self, frame):\n",
    "        ball_distance = 0\n",
    "        ball_degree = 0\n",
    "        return frame, ball_distance, ball_degree\n",
    "    \n",
    "class Display:\n",
    "    \"\"\"Display\"\"\"\n",
    "    def __init__(self, name, height, weight):\n",
    "        self.name = name\n",
    "        self.height = height\n",
    "        self.weight = weight\n",
    "        cv2.namedWindow(name)\n",
    "        \n",
    "    def show(self,image):\n",
    "        cv2.imshow(self.name, image)\n",
    "\n",
    "class Input:\n",
    "    \"\"\"Input\"\"\"\n",
    "    def __init__(self):\n",
    "        self.use_default = 1\n",
    "        self.default_upper = np.array([50,255,255])\n",
    "        self.default_lower = np.array([0,170,170])\n",
    "        self.upper_h = 255\n",
    "        self.lower_h = 0\n",
    "        self.upper_s = 255\n",
    "        self.lower_s = 0\n",
    "        self.upper_v = 255\n",
    "        self.lower_v = 0\n",
    "        self.min_value = 0\n",
    "        self.max_value = 1000\n",
    "        \n",
    "    def nothing(self,x):\n",
    "        pass\n",
    "    \n",
    "    def create_trackbar(self):\n",
    "        self.threshold = Display('Threshold',640,480)\n",
    "        cv2.createTrackbar('Use Default','Threshold',0,1,self.nothing)\n",
    "        cv2.createTrackbar('Upper H','Threshold',0,179,self.nothing)\n",
    "        cv2.createTrackbar('Lower H','Threshold',0,179,self.nothing)\n",
    "        cv2.createTrackbar('Upper S','Threshold',0,255,self.nothing)\n",
    "        cv2.createTrackbar('Lower S','Threshold',0,255,self.nothing)\n",
    "        cv2.createTrackbar('Upper V','Threshold',0,255,self.nothing)\n",
    "        cv2.createTrackbar('Lower V','Threshold',0,255,self.nothing)\n",
    "        cv2.createTrackbar('Min Value','Threshold',0,10000,self.nothing)\n",
    "        cv2.createTrackbar('Max Value','Threshold',0,10000,self.nothing)\n",
    "        \n",
    "    def update_value(self):\n",
    "        self.use_default = cv2.getTrackbarPos('Use Default','Threshold')\n",
    "        self.upper_h = cv2.getTrackbarPos('Upper H','Threshold')\n",
    "        self.lower_h = cv2.getTrackbarPos('Lower H','Threshold')\n",
    "        self.upper_s = cv2.getTrackbarPos('Upper S','Threshold')\n",
    "        self.lower_s = cv2.getTrackbarPos('Lower S','Threshold')\n",
    "        self.upper_v = cv2.getTrackbarPos('Upper V','Threshold')\n",
    "        self.lower_v = cv2.getTrackbarPos('Lower V','Threshold')\n",
    "\n",
    "    def get_value(self):\n",
    "        if(self.use_default is 1):\n",
    "            return self.default_upper, self.default_lower\n",
    "        else:\n",
    "            return np.array([self.upper_h,self.upper_s,self.upper_v]), np.array([self.lower_h,self.lower_s,self.lower_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StepperMotor import *\n",
    "from Tracker import *\n",
    "from threading import Thread\n",
    "\n",
    "cam = Camera(0)\n",
    "inputs = Input()\n",
    "tracker = Tracker()\n",
    "motor = StepperMotor(\"COM3\",115200)\n",
    "display = Display(\"Display\",640,480)\n",
    "\n",
    "#Global Variable\n",
    "is_running = False\n",
    "is_ready_to_move = False\n",
    "is_move_done = False\n",
    "ball_distance = 0\n",
    "ball_degree = 0\n",
    "\n",
    "def get_input():\n",
    "    global is_running\n",
    "\n",
    "    is_running = True\n",
    "    \n",
    "    while(is_running):\n",
    "        inputs.update_value()\n",
    "        value = inputs.get_value()\n",
    "        time.sleep(0.1)\n",
    "        #print(value)\n",
    "\n",
    "def tracking():\n",
    "    global is_running, ball_distance, ball_degree\n",
    "\n",
    "    is_running = True\n",
    "    \n",
    "    cam.connect()\n",
    "    i = 0\n",
    "    while(is_running):\n",
    "        start = time.time()\n",
    "\n",
    "        ret, frame = cam.get_frame()\n",
    "        if ret is False:\n",
    "            print(\"No frame\")\n",
    "            continue\n",
    "\n",
    "        frame = tracker.threshold(frame)\n",
    "        frame, ball_distance, ball_degree = tracker.track(frame)\n",
    "        display.show(frame)\n",
    "        \n",
    "        end = time.time()\n",
    "        print(i,(end-start)*1000)\n",
    "        i = i +1\n",
    "    cam.disconnect()\n",
    "\n",
    "def move_motor():\n",
    "    global is_running,is_ready_to_move, is_move_done, ball_distance, ball_degree\n",
    "\n",
    "    is_running = True\n",
    "    \n",
    "    motor.connect()\n",
    "    \n",
    "    while(is_running):\n",
    "        if(is_ready_to_move and not is_move_done):\n",
    "            motor.move(ball_degree)\n",
    "        #print(ball_distance,ball_degree)\n",
    "        \n",
    "get_input_thread = Thread(target = get_input)\n",
    "tracking_thread = Thread(target = tracking)\n",
    "move_motor_thread = Thread(target = move_motor)\n",
    "\n",
    "inputs.create_trackbar()\n",
    "\n",
    "get_input_thread.start()\n",
    "tracking_thread.start()\n",
    "move_motor_thread.start()\n",
    "\n",
    "while(True):\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key is 27:\n",
    "        is_running = False\n",
    "        break\n",
    "    \n",
    "if(is_running is True):\n",
    "    is_running = False\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
