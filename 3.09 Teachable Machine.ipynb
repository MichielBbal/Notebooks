{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teachable Machine\n",
    "\n",
    "USES OPENCV ANACONDA\n",
    "\n",
    "source:https://teachablemachine.withgoogle.com/\n",
    "\n",
    "## Contents\n",
    "0. Install packages\n",
    "1. Run the script \n",
    "2. Combine prediction with labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install packages\n",
    "\n",
    "Install OpenCV and Tensorflow in Anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run the script from teachable machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: keras_model.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3e1adf4eb002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Load the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'keras_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Create the array of the right shape to feed into the keras model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    109\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[0;32m    112\u001b[0m                   (export_dir,\n\u001b[0;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: keras_model.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = tensorflow.keras.models.load_model('keras_model.h5')\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image = Image.open('schaar.jpg')\n",
    "\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# display the resized image\n",
    "image.show()\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = model.predict(data)\n",
    "print(\"prediction = \"+str(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do some data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combine prediction with labels\n",
    "\n",
    "Define variables based on results, sort the list of variables, return highest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['schaar', 0.8355271], ['papier', 0.09291524], ['steen', 0.071557604]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'schaar'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papier = [\"papier\", prediction[0,0]]\n",
    "steen  = [\"steen\", prediction[0,1]]\n",
    "schaar = [\"schaar\",prediction[0,2]]\n",
    "lijst = [papier,steen, schaar]\n",
    "lijst.sort(key=lambda x: x[1], reverse=True)\n",
    "print(lijst)\n",
    "hoogste = lijst[0]\n",
    "hoogste_class = hoogste[0]\n",
    "hoogste_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. From image classification to object detection\n",
    "source: https://www.instructables.com/Easy-Machine-Learning-Object-Detection-With-Teacha/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvlib\n",
      "  Downloading cvlib-0.2.6.tar.gz (10.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from cvlib) (1.19.3)\n",
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from cvlib) (2.25.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from cvlib) (7.0.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from cvlib) (2.9.0)\n",
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from requests->cvlib) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from requests->cvlib) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from requests->cvlib) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from requests->cvlib) (4.0.0)\n",
      "Building wheels for collected packages: cvlib, imutils, progressbar\n",
      "  Building wheel for cvlib (setup.py): started\n",
      "  Building wheel for cvlib (setup.py): finished with status 'done'\n",
      "  Created wheel for cvlib: filename=cvlib-0.2.6-py3-none-any.whl size=10044621 sha256=4c76d5f763f99508c02b51e48ff8f19ad831a816ffa8e37f9b24a91a0d336334\n",
      "  Stored in directory: c:\\users\\31653\\appdata\\local\\pip\\cache\\wheels\\ab\\cb\\f5\\2d027cae91342418d4a84c6955d080c2e361b60bb72db3f71c\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=f09768a059322e2356ae996374aa1251a573217876f6e2b0720ffe8e9ecdcc98\n",
      "  Stored in directory: c:\\users\\31653\\appdata\\local\\pip\\cache\\wheels\\59\\1b\\52\\0dea905f8278d5514dc4d0be5e251967f8681670cadd3dca89\n",
      "  Building wheel for progressbar (setup.py): startedNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Building wheel for progressbar (setup.py): finished with status 'done'\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12075 sha256=e5f0305df2f46fc6e8c183764d9d5a69b1b3cdf5bd7165d50bac46fa4b0ccd39\n",
      "  Stored in directory: c:\\users\\31653\\appdata\\local\\pip\\cache\\wheels\\2c\\67\\ed\\d84123843c937d7e7f5ba88a270d11036473144143355e2747\n",
      "Successfully built cvlib imutils progressbar\n",
      "Installing collected packages: progressbar, imutils, cvlib\n",
      "Successfully installed cvlib-0.2.6 imutils-0.5.4 progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "%pip install cvlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Collecting pypiwin32\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Collecting comtypes\n",
      "  Downloading comtypes-1.1.9.zip (182 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\31653\\anaconda3\\envs\\opencv\\lib\\site-packages (from pyttsx3) (300)\n",
      "Building wheels for collected packages: comtypes\n",
      "  Building wheel for comtypes (setup.py): started\n",
      "  Building wheel for comtypes (setup.py): finished with status 'done'\n",
      "  Created wheel for comtypes: filename=comtypes-1.1.9-py3-none-any.whl size=164740 sha256=8da7a849cfeb69d1294de8507264f554bd9ac437eb7560eb1f0d0c993264638e\n",
      "  Stored in directory: c:\\users\\31653\\appdata\\local\\pip\\cache\\wheels\\57\\6a\\a9\\37b7e7b9e0384434481589e72aafa1697f0f2aab340bdeba07\n",
      "Successfully built comtypes\n",
      "Installing collected packages: pypiwin32, comtypes, pyttsx3\n",
      "Successfully installed comtypes-1.1.9 pypiwin32-223 pyttsx3-2.90\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov4.cfg from https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov4.weights from https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov3_classes.txt from https://github.com/arunponnusamy/object-detection-opencv/raw/master/yolov3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |                                                                        |\r"
     ]
    }
   ],
   "source": [
    "# OpenCV Common Object Detection\n",
    "#\n",
    "# Michael D'Argenio\n",
    "# mjdargen@gmail.com\n",
    "# https://dargenio.dev\n",
    "# https://github.com/mjdargen\n",
    "# Created: February 6, 2020\n",
    "# Last Modified: February 13, 2021\n",
    "#\n",
    "# My program to execute Arun Ponnusamy's OpenCV wrapper for\n",
    "# a YOLO common object detection model. More info below:\n",
    "# https://www.arunponnusamy.com/yolo-object-detection-opencv-python.html\n",
    "# https://github.com/arunponnusamy/object-detection-opencv/\n",
    "\n",
    "import multiprocessing\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "import pyttsx3\n",
    "\n",
    "\n",
    "# this process is purely for text-to-speech so it doesn't hang processor\n",
    "def speak(speakQ, ):\n",
    "    # initialize text-to-speech object\n",
    "    engine = pyttsx3.init()\n",
    "    # can adjust volume if you'd like\n",
    "    volume = engine.getProperty('volume')\n",
    "    engine.setProperty('volume', volume+0.25)\n",
    "\n",
    "    # keeps program running forever until ctrl+c or window is closed\n",
    "    while True:\n",
    "        # clear out message and reinit skip\n",
    "        msg = \"\"\n",
    "        skip = 0\n",
    "        # retrieve all messages\n",
    "        while not speakQ.empty():\n",
    "            temp = speakQ.get()\n",
    "            # if new, break loop and reset because not newest labels\n",
    "            if '#new#' in temp:\n",
    "                skip = 1\n",
    "                break\n",
    "            # concatenate labels for speech\n",
    "            msg = msg + ', ' + temp\n",
    "        # if we aren't skipping, say the labels\n",
    "        if not skip:\n",
    "            engine.say(msg)\n",
    "            engine.runAndWait()\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # instantiate video capture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # creating a queue to share data to speech process\n",
    "    speakQ = multiprocessing.Queue()\n",
    "    # creating speech process to not hang processor\n",
    "    p1 = multiprocessing.Process(target=speak, args=(speakQ, ))\n",
    "    # starting process 1 - speech\n",
    "    p1.start()\n",
    "\n",
    "    # keeps program running forever until ctrl+c or window is closed\n",
    "    while True:\n",
    "        # capture image\n",
    "        _, img = cap.read()\n",
    "        # use detect common objects model to label objects\n",
    "        bbox, labels, conf = cv.detect_common_objects(img)\n",
    "        # draw labels\n",
    "        img = draw_bbox(img, bbox, labels, conf)\n",
    "        # send unique string denoting new labels being sent to speech\n",
    "        speakQ.put('#new#')\n",
    "        # send each label to text to speech process\n",
    "        for label in labels:\n",
    "            speakQ.put(label.lower())\n",
    "        # display and wait 10ms\n",
    "        cv2.imshow('my webcam', img)\n",
    "        cv2.waitKey(10)\n",
    "\n",
    "    # clean up if you want to remove while loop\n",
    "    cap.release()\n",
    "    p1.terminate()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
