{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michiels Neural Networks Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My first neural network simply using numpy\n",
    "source: https://www.youtube.com/watch?v=kft1AJ9WVDk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting synaptic weights: \n",
      "[[1.417022  ]\n",
      " [1.72032449]\n",
      " [1.00011437]]\n",
      "outputs\n",
      "[[0.73108107]\n",
      " [0.98428749]\n",
      " [0.91812474]\n",
      " [0.93822198]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "training_inputs = np.array([[0,0,1],\n",
    "                           [1,1,1],\n",
    "                           [1,0,1],\n",
    "                           [0,1,1]])\n",
    "\n",
    "training_outputs = np.array([[0,1,1,0]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "synaptic_weights = 2 + np.random.random((3,1)) - 1\n",
    "\n",
    "print('Random starting synaptic weights: ')\n",
    "print(synaptic_weights)\n",
    "\n",
    "for iteration in range (1000):\n",
    "    input_layer = training_inputs\n",
    "    \n",
    "    outputs = sigmoid(np.dot(input_layer, synaptic_weights))\n",
    "    \n",
    "print('outputs')\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As above but improved\n",
    "With sigmoid_derivative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting synaptic weights: \n",
      "[[1.417022  ]\n",
      " [1.72032449]\n",
      " [1.00011437]]\n",
      "Synaptic weights after training\n",
      "[[11.30928823]\n",
      " [-0.2049903 ]\n",
      " [-5.45009058]]\n",
      "Outputs after trainig\n",
      "[[0.00427758]\n",
      " [0.99650944]\n",
      " [0.99715456]\n",
      " [0.00348752]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return  x * (1-x)\n",
    "\n",
    "training_inputs = np.array([[0,0,1],\n",
    "                           [1,1,1],\n",
    "                           [1,0,1],\n",
    "                           [0,1,1]])\n",
    "\n",
    "training_outputs = np.array([[0,1,1,0]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "synaptic_weights = 2 + np.random.random((3,1)) - 1\n",
    "\n",
    "print('Random starting synaptic weights: ')\n",
    "print(synaptic_weights)\n",
    "\n",
    "for iteration in range (50000):\n",
    "    input_layer = training_inputs\n",
    "    \n",
    "    outputs = sigmoid(np.dot(input_layer, synaptic_weights))\n",
    "    \n",
    "    error = training_outputs - outputs\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(outputs)\n",
    "    \n",
    "    synaptic_weights += np.dot(input_layer.T, adjustments)\n",
    "\n",
    "print('Synaptic weights after training')\n",
    "print(synaptic_weights)\n",
    "    \n",
    "print('Outputs after trainig')\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As above but with using class\n",
    "\n",
    "https://www.youtube.com/watch?v=Py4xvZx-A1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "synaptic weights after training\n",
      "[[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]]\n",
      "Input 1: 1\n",
      "Input 2: 0\n",
      "Input 3: 0\n",
      "new situation: input data =  1 0 0\n",
      "output data: \n",
      "[0.99993704]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        self.synaptic_weights = 2 * np.random.random((3,1))-1\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 /(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1-x)\n",
    "    \n",
    "    def train(self, training_inputs, training_outputs, training_iterations):\n",
    "       \n",
    "        for iteration in range(training_iterations):\n",
    "        \n",
    "            output = self.think(training_inputs)\n",
    "            error = training_outputs - output\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "            self.synaptic_weights += adjustments\n",
    "    \n",
    "    def think(self, inputs):\n",
    "        \n",
    "        inputs = inputs.astype(float)\n",
    "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        \n",
    "        return output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    neural_network = NeuralNetwork()\n",
    " \n",
    "    print(neural_network.synaptic_weights)\n",
    "    \n",
    "    training_inputs = np.array([[0,0,1],\n",
    "                           [1,1,1],\n",
    "                           [1,0,1],\n",
    "                           [0,1,1]])\n",
    "\n",
    "    training_outputs = np.array([[0,1,1,0]]).T\n",
    "    \n",
    "    neural_network.train(training_inputs, training_outputs, 10000)\n",
    "    \n",
    "    print('synaptic weights after training')\n",
    "    print(neural_network.synaptic_weights)\n",
    "    \n",
    "    A = str(input(\"Input 1: \"))\n",
    "    B = str(input(\"Input 2: \"))\n",
    "    C = str(input(\"Input 3: \"))\n",
    "    \n",
    "    print('new situation: input data = ', A,B,C)\n",
    "    print (\"output data: \")\n",
    "    print(neural_network.think(np.array([A,B,C])))\n",
    "    ## use A=1 B=0 and C=0 as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the sigmoid function using math / numpy\n",
    "\n",
    "Source: https://squall0032.tumblr.com/post/77300791096/plotting-a-sigmoid-function-using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(1/(1+math.exp(-item)))\n",
    "    return a\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "sig = sigmoid(x)\n",
    "plt.plot(x,sig)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Machine Learning \n",
    "https://www.youtube.com/watch?v=KNAWp2S3w94&t=2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.7510\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 502us/step - loss: 0.7110\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.6771\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.6480\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.6227\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.6005\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.5808\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.5630\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.5469\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.5321\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.5183\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.5054\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.4933\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.4818\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.4708\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.4603\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.4501\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.4404\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.4309\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.4217\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.4128\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.4041\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.3957\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.3874\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.3794\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.3715\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.3638\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.3563\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.3489\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.3417\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.3347\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.3278\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 328us/step - loss: 0.3210\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.3144\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.3080\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.3016\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.2954\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.2894\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.2834\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.2776\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.2719\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.2663\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.2608\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.2555\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2502\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.2451\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.2400\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 492us/step - loss: 0.2351\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.2303\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.2256\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.2209\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.2164\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.2119\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.2076\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.2033\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1991\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1951\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.1910\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1871\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1833\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.1795\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.1758\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 497us/step - loss: 0.1722\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.1687\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 496us/step - loss: 0.1652\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1618\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1585\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.1552\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1521\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.1489\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.1459\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.1429\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.1399\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.1371\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.1342\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.1315\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 0.1288\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.1261\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1236\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.1210\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.1185\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 0.1161\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 329us/step - loss: 0.1137\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.1114\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1091\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1068\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.1047\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.1025\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.1004\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0983\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0963\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.0943\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0924\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.0905\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0886\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0868\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0850\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0833\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0816\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0799\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0783\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0751\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0735\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.0720\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 828us/step - loss: 0.0705\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0691\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0677\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0663\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0649\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0636\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0623\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0610\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 0.0598\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0585\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0573\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0561\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0550\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0539\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0528\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0517\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0506\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0496\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0486\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0476\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0466\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0456\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0447\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.0438\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0429\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0420\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0411\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0403\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0395\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0386\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0379\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0371\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0363\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0356\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 0.0348\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0341\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0334\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 0.0327\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 330us/step - loss: 0.0321\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0314\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0308\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0301\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0295\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0289\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0283\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0277\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0272\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0266\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0261\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0255\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0250\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0245\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 165us/step - loss: 0.0240\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0235\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0230\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0225\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0221\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0216\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0212\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0207\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0203\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0199\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0195\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0191\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0187\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0183\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 501us/step - loss: 0.0179\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0176\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0172\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0168\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0165\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0162\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0158\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0155\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 504us/step - loss: 0.0152\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0149\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0146\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0143\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0140\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0137\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0134\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0131\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0129\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0126\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0123\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0121\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 330us/step - loss: 0.0118\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.0116\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0114\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.0111\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0109\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0107\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 0.0105\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0102\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 0.0100\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0098\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0094\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0092\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0090\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0089\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 0.0087\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0085\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 670us/step - loss: 0.0083\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0081\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0080\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0078\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 165us/step - loss: 0.0077\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0075\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0073\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0072\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0070\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0069\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0068\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0066\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0065\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0064\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0062\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 0.0061\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.0060\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0058\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0057\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0056\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0055\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 835us/step - loss: 0.0054\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0053\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0052\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 669us/step - loss: 0.0051\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 0.0050\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0049\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0048\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0047\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0046\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 328us/step - loss: 0.0045\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0044\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0043\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0042\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0041\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0040\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 497us/step - loss: 0.0039\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 0.0039\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0038\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0037\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 334us/step - loss: 0.0036\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0036\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0035\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0034\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0033\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.0033\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0032\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0031\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0031\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 832us/step - loss: 0.0030\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0029\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0029\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0028\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0028\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 0.0027\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 330us/step - loss: 0.0027\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0026\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0025\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0025\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0024\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0024\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0023\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0023\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.0023\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0022\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0022\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0021\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0021\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0020\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0020\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0019\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0019\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0019\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0018\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0018\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0018\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0017\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0017\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0016\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0016\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0016\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0015\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 0.0015\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0015\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0014\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 497us/step - loss: 0.0014\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0014\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 0.0013\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0013\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0013\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0012\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0012\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0012\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0011\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0011\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0011\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0011\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0010\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 497us/step - loss: 0.0010\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 0.0010\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 9.8108e-04\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 9.6092e-04\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 502us/step - loss: 9.4119e-04\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 9.2186e-04\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 9.0292e-04\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.8438e-04\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 334us/step - loss: 8.6621e-04\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 8.4841e-04\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 8.3099e-04\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 8.1392e-04\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 330us/step - loss: 7.9720e-04\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 7.8082e-04\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 666us/step - loss: 7.6478e-04\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 7.4908e-04\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.3369e-04\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 7.1861e-04\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 334us/step - loss: 7.0386e-04\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 666us/step - loss: 6.8940e-04\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 6.7524e-04\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 6.6137e-04\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 330us/step - loss: 6.4778e-04\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 6.3448e-04\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 6.2145e-04\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 6.0868e-04\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 5.9618e-04\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 5.8393e-04\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 5.7194e-04\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 5.6019e-04\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.4869e-04\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 5.3742e-04\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 5.2638e-04\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 5.1557e-04\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 5.0497e-04\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 4.9460e-04\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 4.8444e-04\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 4.7449e-04\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 4.6474e-04\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 4.5520e-04\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 4.4585e-04\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 4.3669e-04\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 4.2772e-04\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 4.1894e-04\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 4.1033e-04\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 4.0190e-04\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 3.9364e-04\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 3.8556e-04\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 3.7764e-04\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 3.6988e-04\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 3.6228e-04\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 666us/step - loss: 3.5484e-04\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 3.4755e-04\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 3.4041e-04\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 3.3342e-04\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 3.2657e-04\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 3.1987e-04\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 3.1329e-04\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 3.0686e-04\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 3.0056e-04\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.9438e-04\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 2.8834e-04\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.8241e-04\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.7661e-04\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 2.7093e-04\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 2.6537e-04\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.5991e-04\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.5458e-04\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 832us/step - loss: 2.4935e-04\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.4423e-04\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 2.3921e-04\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 2.3430e-04\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 2.2948e-04\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.2477e-04\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.2015e-04\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.1563e-04\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.1120e-04\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 2.0686e-04\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 2.0261e-04\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.9845e-04\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 1.9438e-04\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.9038e-04\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.8647e-04\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 330us/step - loss: 1.8264e-04\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 1.7889e-04\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 1.7522e-04\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 1.7162e-04\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 497us/step - loss: 1.6809e-04\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 1.6464e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 167us/step - loss: 1.6126e-04\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 1.5794e-04\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 1.5470e-04\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 1.5152e-04\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.4841e-04\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 1.4536e-04\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 1.4238e-04\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 1.3945e-04\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.3659e-04\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 1.3378e-04\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.3103e-04\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 1.2834e-04\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 1.2571e-04\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 1.2312e-04\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 166us/step - loss: 1.2059e-04\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.1812e-04\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 1.1569e-04\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 1.1332e-04\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 1.1099e-04\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 827us/step - loss: 1.0871e-04\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 835us/step - loss: 1.0648e-04\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 1.0429e-04\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 1.0215e-04\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0005e-04\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 9.7992e-05\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 9.5981e-05\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 9.4008e-05\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 9.2076e-05\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 9.0185e-05\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 8.8332e-05\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 8.6518e-05\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 502us/step - loss: 8.4742e-05\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 8.3001e-05\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 8.1296e-05\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 7.9626e-05\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 7.7990e-05\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 7.6389e-05\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 7.4819e-05\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 7.3282e-05\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 7.1777e-05\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 7.0303e-05\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 6.8859e-05\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 6.7444e-05\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 6.6060e-05\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 6.4703e-05\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 6.3372e-05\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 6.2071e-05\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 6.0796e-05\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 830us/step - loss: 5.9548e-05\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 5.8324e-05\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 831us/step - loss: 5.7126e-05\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 5.5953e-05\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 5.4804e-05\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 165us/step - loss: 5.3678e-05\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 5.2575e-05\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 997us/step - loss: 5.1495e-05\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 5.0438e-05\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 4.9401e-05\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 4.8387e-05\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 4.7392e-05\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 4.6419e-05\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 4.5465e-05\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 4.4532e-05\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 4.3618e-05\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 326us/step - loss: 4.2722e-05\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 4.1844e-05\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 4.0984e-05\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 4.0143e-05\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 3.9318e-05\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 494us/step - loss: 3.8510e-05\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 3.7720e-05\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 3.6945e-05\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 3.6186e-05\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 3.5442e-05\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 334us/step - loss: 3.4715e-05\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 3.4002e-05\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 3.3302e-05\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 668us/step - loss: 3.2618e-05\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 3.1949e-05\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 329us/step - loss: 3.1293e-05\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 3.0650e-05\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 3.0020e-05\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 2.9404e-05\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.8800e-05\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 2.8208e-05\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 664us/step - loss: 2.7629e-05\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 498us/step - loss: 2.7062e-05\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.6506e-05\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.5961e-05\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 2.5428e-05\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 2.4905e-05\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 2.4393e-05\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.3893e-05\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.3402e-05\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.2921e-05\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 2.2451e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 332us/step - loss: 2.1990e-05\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 500us/step - loss: 2.1538e-05\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 333us/step - loss: 2.1096e-05\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 331us/step - loss: 2.0661e-05\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 499us/step - loss: 2.0237e-05\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 665us/step - loss: 1.9822e-05\n",
      "[[18.987011]]\n"
     ]
    }
   ],
   "source": [
    "#the simplest neural network y = 2x - 1\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])]) #1 neuron, x-value is input for model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# geef x's and y's with y= 2x-1\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
    "\n",
    "model.fit(xs, ys, epochs=500)\n",
    "#predict the y-value for a given x\n",
    "print(model.predict([10.0]))#normaal is het 19 maar bij machine learning wordt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing\n",
    "\n",
    "https://www.youtube.com/watch?v=fNxaJsNG3-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'You love my dog!'\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer(num_words =100)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=r9QjkdSJZ2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'my': 2, 'love': 3, 'dog': 4, 'i': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11}\n",
      "[[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]\n",
      "[[ 5  3  2  4  0  0  0]\n",
      " [ 5  3  2  7  0  0  0]\n",
      " [ 6  3  2  4  0  0  0]\n",
      " [ 8  6  9  2  4 10 11]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'You love my dog!',\n",
    "    'Do you think my dog is amazing?'\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer(num_words =100, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "padded = pad_sequences(sequences, padding='post')\n",
    "print(word_index)\n",
    "print(sequences)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 217)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-793e6471afdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Sarcasm_Headlines_Dataset.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdatastore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extra data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 217)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open ('Sarcasm_Headlines_Dataset.json', 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "urls = []\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['.is_sarcastic'])\n",
    "    urls.append(item['article_link'])\n",
    "    \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences, padding='post')\n",
    "print(padded[0])\n",
    "print(padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Structured Learning\n",
    "https://www.youtube.com/watch?v=N_IS3x5wFNI&list=PLQY2H8rRoyvwLbzbnKJ59NkZvQAW9wLbx&index=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_structured_learning as nsl\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
